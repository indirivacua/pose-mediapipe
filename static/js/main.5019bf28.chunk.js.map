{"version":3,"sources":["utilities.js","App.js","index.js"],"names":["STATE","model","modelConfig","scoreThreshold","enableTracking","poseDetection","BlazePose","params","DEFAULT_LINE_WIDTH","DEFAULT_RADIUS","COLOR_PALETTE","drawResultsPoses","ctx","poses","drawResultPoses","pose","keypoints","keypointInd","getKeypointIndexBySide","fillStyle","strokeStyle","lineWidth","middle","i","drawKeypointPoses","left","right","drawKeypointsPoses","poseId","color","getAdjacentPairs","forEach","j","kp1","kp2","score1","score","score2","beginPath","moveTo","x","y","lineTo","stroke","drawSkeletonPoses","id","keypoint","circle","Path2D","arc","Math","PI","fill","App","webcamRef","useRef","canvasRef","runCoco","a","detectorConfig","runtime","solutionPath","modelType","detector","setInterval","detect","current","video","readyState","videoWidth","videoHeight","width","height","image","estimationConfig","enableSmoothing","estimatePoses","getContext","useEffect","className","ref","muted","style","position","marginLeft","marginRight","textAlign","zindex","ReactDOM","render","StrictMode","document","getElementById"],"mappings":"8ZAQMA,EAAQ,CACZC,MAAO,GACPC,YAAa,IAQfF,EAAME,YAAN,eALuB,CACrBC,eAAgB,GAChBC,gBAAgB,IAIlBJ,EAAMC,MAAQI,IAA8BC,UAE5C,IAAMC,EAAS,CAAEP,QAAOQ,mBAhBG,EAgBiBC,eAfrB,GAqCjBC,EAAgB,CACpB,UAAW,UAAW,UAAW,UAAW,UAAW,UAAW,UAClE,UAAW,UAAW,UAAW,UAAW,UAAW,UAAW,UAClE,UAAW,UAAW,UAAW,UAAW,UAAW,WAOlD,SAASC,EAAiBC,EAAKC,GAAQ,IAAD,gBACxBA,GADwB,IAC3C,2BAA0B,CACxBC,EAAgBF,EADQ,UADiB,+BAU7C,SAASE,EAAgBF,EAAKG,GACN,MAAlBA,EAAKC,YAUX,SAA4BJ,EAAKI,GAC/B,IAAMC,EACFZ,IAAmBa,uBAAuBX,EAAOP,MAAMC,OAC3DW,EAAIO,UAAY,MAChBP,EAAIQ,YAAc,QAClBR,EAAIS,UAAYd,EAAOC,mBALmB,oBAO1BS,EAAYK,QAPc,IAO1C,2BAAoC,CAAC,IAA1BC,EAAyB,QAClCC,EAAkBZ,EAAKI,EAAUO,KARO,8BAW1CX,EAAIO,UAAY,QAX0B,oBAY1BF,EAAYQ,MAZc,IAY1C,2BAAkC,CAAC,IAAxBF,EAAuB,QAChCC,EAAkBZ,EAAKI,EAAUO,KAbO,8BAgB1CX,EAAIO,UAAY,SAhB0B,oBAiB1BF,EAAYS,OAjBc,IAiB1C,2BAAmC,CAAC,IAAzBH,EAAwB,QACjCC,EAAkBZ,EAAKI,EAAUO,KAlBO,+BATxCI,CAAmBf,EAAKG,EAAKC,WAgDjC,SAA2BJ,EAAKI,EAAWY,GAEzC,IAAMC,EAAQtB,EAAOP,MAAME,YAAYE,gBAA4B,MAAVwB,EACrDlB,EAAckB,EAAS,IACvB,QACJhB,EAAIO,UAAYU,EAChBjB,EAAIQ,YAAcS,EAClBjB,EAAIS,UAAYd,EAAOC,mBAEvBH,IAAmByB,iBAAiBvB,EAAOP,MAAMC,OAAO8B,SAAQ,YAEO,IAAD,mBADJR,EACI,KADDS,EACC,KAC9DC,EAAMjB,EAAUO,GAChBW,EAAMlB,EAAUgB,GAGhBG,EAAsB,MAAbF,EAAIG,MAAgBH,EAAIG,MAAQ,EACzCC,EAAsB,MAAbH,EAAIE,MAAgBF,EAAIE,MAAQ,EACzCjC,EAAiBI,EAAOP,MAAME,YAAYC,gBAAkB,EAE9DgC,GAAUhC,GAAkBkC,GAAUlC,IACxCS,EAAI0B,YACJ1B,EAAI2B,OAAON,EAAIO,EAAGP,EAAIQ,GACtB7B,EAAI8B,OAAOR,EAAIM,EAAGN,EAAIO,GACtB7B,EAAI+B,aAvENC,CAAkBhC,EAAKG,EAAKC,UAAWD,EAAK8B,KA8BhD,SAASrB,EAAkBZ,EAAKkC,GAK9B,IAHgC,MAAlBA,EAASV,MAAgBU,EAASV,MAAQ,KACjC7B,EAAOP,MAAME,YAAYC,gBAAkB,GAErC,CAC3B,IAAM4C,EAAS,IAAIC,OACnBD,EAAOE,IAAIH,EAASN,EAAGM,EAASL,EAAGlC,EAAOE,eAAgB,EAAG,EAAIyC,KAAKC,IACtEvC,EAAIwC,KAAKL,GACTnC,EAAI+B,OAAOI,ICUAM,MApGf,WACE,IAAMC,EAAYC,iBAAO,MACnBC,EAAYD,iBAAO,MAGnBE,EAAO,uCAAG,gCAAAC,EAAA,6DAIRzD,EAAQI,IAA8BC,UACtCqD,EAAiB,CACrBC,QAAS,YACTC,aAAc,+CAEdC,UAAW,QATC,SAWSzD,IAA6BJ,EAAO0D,GAX7C,OAWRI,EAXQ,OAcdC,aAAY,WACVC,EAAOF,KACN,IAhBW,2CAAH,qDAmBPE,EAAM,uCAAG,WAAOF,GAAP,yBAAAL,EAAA,yDAGkB,qBAAtBJ,EAAUY,SACK,OAAtBZ,EAAUY,SAC6B,IAAvCZ,EAAUY,QAAQC,MAAMC,WALb,wBAQLD,EAAQb,EAAUY,QAAQC,MAC1BE,EAAaf,EAAUY,QAAQC,MAAME,WACrCC,EAAchB,EAAUY,QAAQC,MAAMG,YAG5ChB,EAAUY,QAAQC,MAAMI,MAAQF,EAChCf,EAAUY,QAAQC,MAAMK,OAASF,EAGjCd,EAAUU,QAAQK,MAAQF,EAC1Bb,EAAUU,QAAQM,OAASF,EAKrBG,EAAQN,EACRO,EAAmB,CAACC,iBAAiB,GAxBhC,UAyBSZ,EAASa,cAAcH,EAAOC,GAzBvC,QAyBL7D,EAzBK,OAgCXF,EAJY6C,EAAUU,QAAQW,WAAW,MAInBhE,GAhCX,4CAAH,sDAsCZ,OAFAiE,qBAAU,WAAKrB,MAAW,IAGxB,yBAAKsB,UAAU,OACb,4BAAQA,UAAU,cAChB,kBAAC,IAAD,CACEC,IAAK1B,EACL2B,OAAO,EACPC,MAAO,CACLC,SAAU,WACVC,WAAY,OACZC,YAAa,OACb5D,KAAM,EACNC,MAAO,EACP4D,UAAW,SACXC,OAAQ,EACRhB,MAAO,IACPC,OAAQ,OAIZ,4BACEQ,IAAKxB,EACL0B,MAAO,CACLC,SAAU,WACVC,WAAY,OACZC,YAAa,OACb5D,KAAM,EACNC,MAAO,EACP4D,UAAW,SACXC,OAAQ,EACRhB,MAAO,IACPC,OAAQ,UCtGpBgB,IAASC,OACP,kBAAC,IAAMC,WAAP,KACE,kBAAC,EAAD,OAEFC,SAASC,eAAe,W","file":"static/js/main.5019bf28.chunk.js","sourcesContent":["import * as poseDetection from '@tensorflow-models/pose-detection';\r\n//---------------------------------------------------------\r\n//----------------------DRAW POSES-------------------------\r\n//---------------------------------------------------------\r\n\r\nconst DEFAULT_LINE_WIDTH = 2;\r\nconst DEFAULT_RADIUS = 4;\r\n\r\nconst STATE = {\r\n  model: '',\r\n  modelConfig: {}\r\n};\r\n\r\nconst MOVENET_CONFIG = {\r\n  scoreThreshold: 0.3,\r\n  enableTracking: false\r\n};\r\n\r\nSTATE.modelConfig = {...MOVENET_CONFIG};\r\nSTATE.model = poseDetection.SupportedModels.BlazePose;\r\n\r\nconst params = { STATE, DEFAULT_LINE_WIDTH, DEFAULT_RADIUS };\r\n\r\n// #ffffff - White\r\n// #800000 - Maroon\r\n// #469990 - Malachite\r\n// #e6194b - Crimson\r\n// #42d4f4 - Picton Blue\r\n// #fabed4 - Cupid\r\n// #aaffc3 - Mint Green\r\n// #9a6324 - Kumera\r\n// #000075 - Navy Blue\r\n// #f58231 - Jaffa\r\n// #4363d8 - Royal Blue\r\n// #ffd8b1 - Caramel\r\n// #dcbeff - Mauve\r\n// #808000 - Olive\r\n// #ffe119 - Candlelight\r\n// #911eb4 - Seance\r\n// #bfef45 - Inchworm\r\n// #f032e6 - Razzle Dazzle Rose\r\n// #3cb44b - Chateau Green\r\n// #a9a9a9 - Silver Chalice\r\nconst COLOR_PALETTE = [\r\n  '#ffffff', '#800000', '#469990', '#e6194b', '#42d4f4', '#fabed4', '#aaffc3',\r\n  '#9a6324', '#000075', '#f58231', '#4363d8', '#ffd8b1', '#dcbeff', '#808000',\r\n  '#ffe119', '#911eb4', '#bfef45', '#f032e6', '#3cb44b', '#a9a9a9'\r\n];\r\n \r\n/**\r\n * Draw the keypoints and skeleton on the video.\r\n * @param poses A list of poses to render.\r\n */\r\nexport function drawResultsPoses(ctx, poses) {\r\n  for (const pose of poses) {\r\n    drawResultPoses(ctx, pose);\r\n  }\r\n}\r\n\r\n/**\r\n * Draw the keypoints and skeleton on the video.\r\n * @param pose A pose with keypoints to render.\r\n */\r\nfunction drawResultPoses(ctx, pose) {\r\n  if (pose.keypoints != null) {\r\n    drawKeypointsPoses(ctx, pose.keypoints);\r\n    drawSkeletonPoses(ctx, pose.keypoints, pose.id);\r\n  }\r\n}\r\n\r\n/**\r\n * Draw the keypoints on the video.\r\n * @param keypoints A list of keypoints.\r\n */\r\nfunction drawKeypointsPoses(ctx, keypoints) {\r\n  const keypointInd =\r\n      poseDetection.util.getKeypointIndexBySide(params.STATE.model);\r\n  ctx.fillStyle = 'Red';\r\n  ctx.strokeStyle = 'White';\r\n  ctx.lineWidth = params.DEFAULT_LINE_WIDTH;\r\n\r\n  for (const i of keypointInd.middle) {\r\n    drawKeypointPoses(ctx, keypoints[i]);\r\n  }\r\n\r\n  ctx.fillStyle = 'Green';\r\n  for (const i of keypointInd.left) {\r\n    drawKeypointPoses(ctx, keypoints[i]);\r\n  }\r\n\r\n  ctx.fillStyle = 'Orange';\r\n  for (const i of keypointInd.right) {\r\n    drawKeypointPoses(ctx, keypoints[i]);\r\n  }\r\n}\r\n\r\nfunction drawKeypointPoses(ctx, keypoint) {\r\n  // If score is null, just show the keypoint.\r\n  const score = keypoint.score != null ? keypoint.score : 1;\r\n  const scoreThreshold = params.STATE.modelConfig.scoreThreshold || 0;\r\n\r\n  if (score >= scoreThreshold) {\r\n    const circle = new Path2D();\r\n    circle.arc(keypoint.x, keypoint.y, params.DEFAULT_RADIUS, 0, 2 * Math.PI);\r\n    ctx.fill(circle);\r\n    ctx.stroke(circle);\r\n  }\r\n}\r\n\r\n/**\r\n * Draw the skeleton of a body on the video.\r\n * @param keypoints A list of keypoints.\r\n */\r\nfunction drawSkeletonPoses(ctx, keypoints, poseId) {\r\n  // Each poseId is mapped to a color in the color palette.\r\n  const color = params.STATE.modelConfig.enableTracking && poseId != null ?\r\n      COLOR_PALETTE[poseId % 20] :\r\n      'White';\r\n  ctx.fillStyle = color;\r\n  ctx.strokeStyle = color;\r\n  ctx.lineWidth = params.DEFAULT_LINE_WIDTH;\r\n\r\n  poseDetection.util.getAdjacentPairs(params.STATE.model).forEach(([\r\n                                                                    i, j\r\n                                                                  ]) => {\r\n    const kp1 = keypoints[i];\r\n    const kp2 = keypoints[j];\r\n\r\n    // If score is null, just show the keypoint.\r\n    const score1 = kp1.score != null ? kp1.score : 1;\r\n    const score2 = kp2.score != null ? kp2.score : 1;\r\n    const scoreThreshold = params.STATE.modelConfig.scoreThreshold || 0;\r\n\r\n    if (score1 >= scoreThreshold && score2 >= scoreThreshold) {\r\n      ctx.beginPath();\r\n      ctx.moveTo(kp1.x, kp1.y);\r\n      ctx.lineTo(kp2.x, kp2.y);\r\n      ctx.stroke();\r\n    }\r\n  });\r\n}","// Import dependencies\nimport React, { useRef, useState, useEffect } from \"react\";\n// 1. TODO - Import required model here\n// e.g. import * as tfmodel from \"@tensorflow-models/tfmodel\";\nimport * as poseDetection from '@tensorflow-models/pose-detection';\nimport '@tensorflow/tfjs-core';\n// Register WebGL backend.\nimport '@tensorflow/tfjs-backend-webgl';\nimport '@mediapipe/pose';\nimport Webcam from \"react-webcam\";\nimport \"./App.css\";\n// 2. TODO - Import drawing utility here\n// e.g. import { drawRect } from \"./utilities\";\nimport { drawResultsPoses } from \"./utilities\";\n\nfunction App() {\n  const webcamRef = useRef(null);\n  const canvasRef = useRef(null);\n\n  // Main function\n  const runCoco = async () => {\n    // 3. TODO - Load network \n    // e.g. const net = await cocossd.load();\n    // Create a detector.\n    const model = poseDetection.SupportedModels.BlazePose;\n    const detectorConfig = {\n      runtime: 'mediapipe',\n      solutionPath: 'https://cdn.jsdelivr.net/npm/@mediapipe/pose',\n                    // or 'base/node_modules/@mediapipe/pose' in npm.\n      modelType: 'lite'\n    };\n    const detector = await poseDetection.createDetector(model, detectorConfig);\n    \n    //  Loop and detect hands\n    setInterval(() => {\n      detect(detector);\n    }, 10);\n  };\n\n  const detect = async (detector) => {\n    // Check data is available\n    if (\n      typeof webcamRef.current !== \"undefined\" &&\n      webcamRef.current !== null &&\n      webcamRef.current.video.readyState === 4\n    ) {\n      // Get Video Properties\n      const video = webcamRef.current.video;\n      const videoWidth = webcamRef.current.video.videoWidth;\n      const videoHeight = webcamRef.current.video.videoHeight;\n\n      // Set video width\n      webcamRef.current.video.width = videoWidth;\n      webcamRef.current.video.height = videoHeight;\n\n      // Set canvas height and width\n      canvasRef.current.width = videoWidth;\n      canvasRef.current.height = videoHeight;\n\n      // 4. TODO - Make Detections\n      // e.g. const obj = await net.detect(video);\n      // Pass in a video stream to the model to detect poses.\n      const image = video;\n      const estimationConfig = {enableSmoothing: true};\n      const poses = await detector.estimatePoses(image, estimationConfig);\n\n      // Draw mesh\n      const ctx = canvasRef.current.getContext(\"2d\");\n\n      // 5. TODO - Update drawing utility\n      // drawSomething(obj, ctx)  \n      drawResultsPoses(ctx, poses);\n    }\n  };\n\n  useEffect(()=>{runCoco()},[]);\n\n  return (\n    <div className=\"App\">\n      <header className=\"App-header\">\n        <Webcam\n          ref={webcamRef}\n          muted={true} \n          style={{\n            position: \"absolute\",\n            marginLeft: \"auto\",\n            marginRight: \"auto\",\n            left: 0,\n            right: 0,\n            textAlign: \"center\",\n            zindex: 9,\n            width: 640,\n            height: 480,\n          }}\n        />\n\n        <canvas\n          ref={canvasRef}\n          style={{\n            position: \"absolute\",\n            marginLeft: \"auto\",\n            marginRight: \"auto\",\n            left: 0,\n            right: 0,\n            textAlign: \"center\",\n            zindex: 8,\n            width: 640,\n            height: 480,\n          }}\n        />\n      </header>\n    </div>\n  );\n}\n\nexport default App;\n","import React from 'react';\nimport ReactDOM from 'react-dom';\nimport './index.css';\nimport App from './App';\n\nReactDOM.render(\n  <React.StrictMode>\n    <App />\n  </React.StrictMode>,\n  document.getElementById('root')\n);"],"sourceRoot":""}